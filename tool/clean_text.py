"""
æ–‡æœ¬æ•°æ®æ¸…æ´—å·¥å…·
ç”¨äºæ¸…ç†TXTæ–‡ä»¶ä¸­çš„å¹¿å‘Šã€å¤šä½™ç©ºæ ¼ã€æ¢è¡Œç­‰æ— ç”¨å†…å®¹

ä½¿ç”¨æ–¹æ³•ï¼š
    python tool/clean_text.py [é€‰é¡¹]

é€‰é¡¹ï¼š
    --input DIR         è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤ï¼š./dataï¼‰
    --output DIR        è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./data_cleanedï¼‰
    --preview FILE      é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºæ¸…æ´—æ•ˆæœï¼Œä¸ä¿å­˜
    --inplace           å°±åœ°ä¿®æ”¹ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼Œå±é™©ï¼ï¼‰
    --min-length N      æœ€å°æ–‡æœ¬å—é•¿åº¦ï¼ˆé»˜è®¤ï¼š50ï¼‰
    --help              æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹ï¼š
    # æ¸…æ´—dataç›®å½•çš„æ‰€æœ‰TXTæ–‡ä»¶
    python tool/clean_text.py

    # é¢„è§ˆå•ä¸ªæ–‡ä»¶çš„æ¸…æ´—æ•ˆæœ
    python tool/clean_text.py --preview data/01.å…»ç‹—å®å…¸.txt

    # å°±åœ°ä¿®æ”¹ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
    python tool/clean_text.py --inplace
"""

import sys
import io
import os
import re
import argparse
from pathlib import Path

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


# ========== æ¸…æ´—é…ç½® ==========

# å¹¿å‘Šå’Œåƒåœ¾å…³é”®è¯ï¼ˆå‚è€ƒ config.pyï¼‰
SPAM_KEYWORDS = [
    # å¹¿å‘Šç›¸å…³
    'pinmuch', 'å“å“å“', 'ç½‘è´­è¿”åˆ©',
    # ç›—ç‰ˆæ°´å°
    'è·å–æœ¬ä¹¦PDFå…¨æ–‡', 'è¯·å‰å¾€', 'æœç´¢è¯¥ä¹¦å',
    'æ¬¢é€Ÿè¯å¤¯æ‚£PDF', 'å…¨æ–‡ï¼Œè¯·å‰å¾€',
    # ç½‘å€é“¾æ¥
    'http://', 'https://', 'www.',
    # æ¨å¹¿å†…å®¹
    'ç²¾å“èµ„æº', 'æ‰«ç å…³æ³¨', 'å¾®ä¿¡å…¬ä¼—å·', 'å…¬ä¼—å·',
    'å°½åœ¨""', 'çŒ®ç»™', 'ä¸“ä¸šå…³çˆ±',
    # ç‰ˆæƒå£°æ˜
    'ç‰ˆæƒæ‰€æœ‰', 'ä¿ç•™æ‰€æœ‰æƒåˆ©',
    # å…¶ä»–æ— ç”¨å†…å®¹
    'æµäº§åº·å¤', 'åšä¸ªçˆ±å¥¹çš„ç”·äºº', 'åšä¸ªä½“å·±çš„å¥³å­',
]

# æœ€å°æœ‰ç”¨æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
MIN_USEFUL_LENGTH = 50


class TextCleaner:
    """æ–‡æœ¬æ¸…æ´—å™¨"""

    def __init__(self, spam_keywords=None, min_length=None):
        """
        åˆå§‹åŒ–æ¸…æ´—å™¨

        Args:
            spam_keywords: åƒåœ¾å…³é”®è¯åˆ—è¡¨
            min_length: æœ€å°æœ‰ç”¨æ–‡æœ¬é•¿åº¦
        """
        self.spam_keywords = spam_keywords or SPAM_KEYWORDS
        self.min_length = min_length or MIN_USEFUL_LENGTH

        self.stats = {
            'total_lines': 0,
            'removed_lines': 0,
            'spam_filtered': 0,
            'empty_filtered': 0,
            'short_filtered': 0
        }

    def contains_spam(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«åƒåœ¾å…³é”®è¯"""
        text_lower = text.lower()
        for keyword in self.spam_keywords:
            if keyword.lower() in text_lower:
                return True, keyword
        return False, None

    def clean_line(self, line):
        """æ¸…æ´—å•è¡Œæ–‡æœ¬"""
        # ç§»é™¤ä¸¤ç«¯ç©ºæ ¼
        line = line.strip()

        # ç§»é™¤å¤šä½™ç©ºæ ¼ï¼ˆè¿ç»­ç©ºæ ¼è½¬ä¸ºå•ä¸ªï¼‰
        line = re.sub(r'\s+', ' ', line)

        return line

    def clean_text(self, text):
        """
        æ¸…æ´—æ–‡æœ¬å†…å®¹

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            cleaned_text: æ¸…æ´—åçš„æ–‡æœ¬
            stats: æ¸…æ´—ç»Ÿè®¡ä¿¡æ¯
        """
        lines = text.split('\n')
        cleaned_lines = []

        self.stats['total_lines'] = len(lines)

        for line in lines:
            # æ¸…æ´—è¡Œ
            cleaned_line = self.clean_line(line)

            # è¿‡æ»¤ç©ºè¡Œ
            if not cleaned_line:
                self.stats['empty_filtered'] += 1
                self.stats['removed_lines'] += 1
                continue

            # è¿‡æ»¤åƒåœ¾å†…å®¹
            is_spam, keyword = self.contains_spam(cleaned_line)
            if is_spam:
                self.stats['spam_filtered'] += 1
                self.stats['removed_lines'] += 1
                continue

            # è¿‡æ»¤è¿‡çŸ­æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯é¡µç ã€æ ‡é¢˜ç­‰ï¼‰
            if len(cleaned_line) < self.min_length:
                self.stats['short_filtered'] += 1
                self.stats['removed_lines'] += 1
                continue

            cleaned_lines.append(cleaned_line)

        # åˆå¹¶è¡Œï¼Œç”¨åŒæ¢è¡Œåˆ†éš”ï¼ˆä¿æŒæ®µè½ç»“æ„ï¼‰
        cleaned_text = '\n\n'.join(cleaned_lines)

        # ç§»é™¤3ä¸ªä»¥ä¸Šè¿ç»­æ¢è¡Œ
        cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

        return cleaned_text, self.stats.copy()

    def clean_file(self, input_path, output_path=None):
        """
        æ¸…æ´—å•ä¸ªæ–‡ä»¶

        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆNoneåˆ™ä¸ä¿å­˜ï¼‰

        Returns:
            cleaned_text: æ¸…æ´—åçš„æ–‡æœ¬
            stats: ç»Ÿè®¡ä¿¡æ¯
        """
        # é‡ç½®ç»Ÿè®¡
        self.stats = {
            'total_lines': 0,
            'removed_lines': 0,
            'spam_filtered': 0,
            'empty_filtered': 0,
            'short_filtered': 0
        }

        # è¯»å–åŸæ–‡ä»¶
        with open(input_path, 'r', encoding='utf-8') as f:
            text = f.read()

        # æ¸…æ´—æ–‡æœ¬
        cleaned_text, stats = self.clean_text(text)

        # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼‰
        if output_path:
            output_dir = os.path.dirname(output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(cleaned_text)

        return cleaned_text, stats


def preview_file(file_path, cleaner):
    """é¢„è§ˆæ–‡ä»¶æ¸…æ´—æ•ˆæœ"""
    print("=" * 80)
    print(f"ğŸ“„ æ–‡ä»¶: {file_path}")
    print("=" * 80)

    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    # æ¸…æ´—æ–‡ä»¶ï¼ˆä¸ä¿å­˜ï¼‰
    cleaned_text, stats = cleaner.clean_file(file_path)

    # æ˜¾ç¤ºç»Ÿè®¡
    print("\nğŸ“Š æ¸…æ´—ç»Ÿè®¡:")
    print(f"  - æ€»è¡Œæ•°: {stats['total_lines']}")
    print(f"  - ç§»é™¤è¡Œæ•°: {stats['removed_lines']} ({stats['removed_lines']/stats['total_lines']*100:.1f}%)")
    print(f"    â€¢ ç©ºè¡Œ: {stats['empty_filtered']}")
    print(f"    â€¢ åƒåœ¾å†…å®¹: {stats['spam_filtered']}")
    print(f"    â€¢ è¿‡çŸ­æ–‡æœ¬: {stats['short_filtered']}")
    print(f"  - ä¿ç•™è¡Œæ•°: {stats['total_lines'] - stats['removed_lines']}")

    # æ˜¾ç¤ºå‰500å­—ç¬¦é¢„è§ˆ
    print("\nğŸ“ æ¸…æ´—åé¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
    print("-" * 80)
    print(cleaned_text[:500])
    if len(cleaned_text) > 500:
        print("\n... ï¼ˆçœç•¥å‰©ä½™ {} å­—ç¬¦ï¼‰".format(len(cleaned_text) - 500))
    print("-" * 80)

    print(f"\nğŸ’¾ æ¸…æ´—åæ–‡æœ¬é•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
    print("=" * 80)


def clean_directory(input_dir, output_dir, cleaner, inplace=False):
    """æ¸…æ´—ç›®å½•ä¸­çš„æ‰€æœ‰TXTæ–‡ä»¶"""
    print("=" * 80)
    print("ğŸ§¹ æ‰¹é‡æ¸…æ´—TXTæ–‡ä»¶")
    print("=" * 80)
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir if not inplace else 'åŸåœ°ä¿®æ”¹'}")
    print(f"æœ€å°æ–‡æœ¬é•¿åº¦: {cleaner.min_length} å­—ç¬¦")
    print(f"åƒåœ¾å…³é”®è¯æ•°: {len(cleaner.spam_keywords)} ä¸ª")
    print("=" * 80)

    # æŸ¥æ‰¾æ‰€æœ‰TXTæ–‡ä»¶
    txt_files = list(Path(input_dir).glob('**/*.txt'))

    if not txt_files:
        print(f"\nâŒ æœªæ‰¾åˆ°TXTæ–‡ä»¶: {input_dir}")
        return

    print(f"\næ‰¾åˆ° {len(txt_files)} ä¸ªTXTæ–‡ä»¶\n")

    total_stats = {
        'files_processed': 0,
        'total_lines': 0,
        'removed_lines': 0,
        'spam_filtered': 0,
        'empty_filtered': 0,
        'short_filtered': 0
    }

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, txt_file in enumerate(txt_files, 1):
        file_name = txt_file.name
        print(f"[{i}/{len(txt_files)}] æ¸…æ´—: {file_name}...")

        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if inplace:
            output_path = str(txt_file)
        else:
            relative_path = txt_file.relative_to(input_dir)
            output_path = os.path.join(output_dir, relative_path)

        try:
            # æ¸…æ´—æ–‡ä»¶
            cleaned_text, stats = cleaner.clean_file(str(txt_file), output_path)

            # ç´¯è®¡ç»Ÿè®¡
            total_stats['files_processed'] += 1
            total_stats['total_lines'] += stats['total_lines']
            total_stats['removed_lines'] += stats['removed_lines']
            total_stats['spam_filtered'] += stats['spam_filtered']
            total_stats['empty_filtered'] += stats['empty_filtered']
            total_stats['short_filtered'] += stats['short_filtered']

            # æ˜¾ç¤ºè¿›åº¦
            print(f"  âœ… å®Œæˆ: ç§»é™¤ {stats['removed_lines']}/{stats['total_lines']} è¡Œ "
                  f"({stats['removed_lines']/stats['total_lines']*100:.1f}%)")

        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")

    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸…æ´—æ€»ç»“")
    print("=" * 80)
    print(f"å¤„ç†æ–‡ä»¶æ•°: {total_stats['files_processed']}")
    print(f"æ€»è¡Œæ•°: {total_stats['total_lines']}")
    print(f"ç§»é™¤è¡Œæ•°: {total_stats['removed_lines']} ({total_stats['removed_lines']/total_stats['total_lines']*100:.1f}%)")
    print(f"  - ç©ºè¡Œ: {total_stats['empty_filtered']}")
    print(f"  - åƒåœ¾å†…å®¹: {total_stats['spam_filtered']}")
    print(f"  - è¿‡çŸ­æ–‡æœ¬: {total_stats['short_filtered']}")
    print(f"ä¿ç•™è¡Œæ•°: {total_stats['total_lines'] - total_stats['removed_lines']}")
    print("=" * 80)

    if not inplace:
        print(f"\nâœ… æ¸…æ´—åçš„æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")
        print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥æ¸…æ´—æ•ˆæœï¼Œç¡®è®¤æ— è¯¯åå¯å¤åˆ¶åˆ°dataç›®å½•")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ–‡æœ¬æ•°æ®æ¸…æ´—å·¥å…· - å»é™¤å¹¿å‘Šã€å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
    # æ¸…æ´—dataç›®å½•çš„æ‰€æœ‰TXTæ–‡ä»¶åˆ°data_cleanedç›®å½•
    python tool/clean_text.py

    # é¢„è§ˆå•ä¸ªæ–‡ä»¶çš„æ¸…æ´—æ•ˆæœ
    python tool/clean_text.py --preview data/01.å…»ç‹—å®å…¸.txt

    # è‡ªå®šä¹‰è¾“å…¥è¾“å‡ºç›®å½•
    python tool/clean_text.py --input ./raw_data --output ./cleaned_data

    # å°±åœ°ä¿®æ”¹ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼‰
    python tool/clean_text.py --inplace --input ./data

    # è‡ªå®šä¹‰æœ€å°æ–‡æœ¬é•¿åº¦
    python tool/clean_text.py --min-length 100
        """
    )

    parser.add_argument('--input', default='./data',
                        help='è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤ï¼š./dataï¼‰')
    parser.add_argument('--output', default='./data_cleaned',
                        help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./data_cleanedï¼‰')
    parser.add_argument('--preview', metavar='FILE',
                        help='é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºæ¸…æ´—æ•ˆæœï¼Œä¸ä¿å­˜')
    parser.add_argument('--inplace', action='store_true',
                        help='å°±åœ°ä¿®æ”¹ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼Œå±é™©ï¼ï¼‰')
    parser.add_argument('--min-length', type=int, default=50,
                        help='æœ€å°æ–‡æœ¬å—é•¿åº¦ï¼ˆé»˜è®¤ï¼š50ï¼‰')

    args = parser.parse_args()

    # åˆ›å»ºæ¸…æ´—å™¨
    cleaner = TextCleaner(
        spam_keywords=SPAM_KEYWORDS,
        min_length=args.min_length
    )

    # é¢„è§ˆæ¨¡å¼
    if args.preview:
        preview_file(args.preview, cleaner)
        return

    # å°±åœ°ä¿®æ”¹è­¦å‘Š
    if args.inplace:
        print("\nâš ï¸  è­¦å‘Šï¼šä½ é€‰æ‹©äº† --inplace æ¨¡å¼ï¼Œè¿™å°†è¦†ç›–åŸæ–‡ä»¶ï¼")
        response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): ")
        if response.lower() not in ['yes', 'y']:
            print("å·²å–æ¶ˆæ“ä½œ")
            return

    # æ‰¹é‡æ¸…æ´—
    clean_directory(
        input_dir=args.input,
        output_dir=args.output if not args.inplace else args.input,
        cleaner=cleaner,
        inplace=args.inplace
    )


if __name__ == "__main__":
    main()

